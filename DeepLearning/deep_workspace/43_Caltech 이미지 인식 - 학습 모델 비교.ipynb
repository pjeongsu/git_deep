{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 메시지가 안나오게..\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 기본\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import missingno\n",
    "\n",
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 교차 검증 함수\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# 학습 데이터와 검증데이터로 나누는 함수\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 전처리\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 평가함수\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 머신러닝 알고리즘 - 분류\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 머신러닝 알고리즘 - 회귀\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 군집\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "# 차원축소\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# 딥러닝\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# 다중분류를 위한 핫-윈 인코더\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 저장된 딥러닝 모델을 복구하는 함수\n",
    "from keras.models import load_model\n",
    "\n",
    "# epoch마다 모델을 저장하는 함수\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 더이상 성능 향상이 이루어지지 않는다면 조기 중단시킬 수 있는 함수\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 문장을 잘라준다.\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence \n",
    "\n",
    "# 이미지 생성자\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# VGG16 모델(이미 학습이 완료되어 있는 이미지 인식 모델)\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# 전처리, 활성 함수 셋팅\n",
    "from keras import optimizers\n",
    "\n",
    "# 저장\n",
    "import pickle\n",
    "\n",
    "# 시간 모듈\n",
    "import time\n",
    "\n",
    "# 이미지 조작을 위한\n",
    "from PIL import Image\n",
    "\n",
    "import os, glob\n",
    "\n",
    "# 그래프 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# gpu 사용 초기화 및 할당\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기\n",
    "X_train, X_test, y_train, y_test = np.load('img/calthec_new.npy',\n",
    "                                          allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화(0 ~ 1 사이로..)\n",
    "X_train = X_train.astype('float') / 256\n",
    "X_test = X_test.astype('float') / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'img/101_new'\n",
    "\n",
    "# 폴더의 이름을 가져와 결과데이터를 구성한다.\n",
    "a1 = os.walk(root_dir)\n",
    "catogories = list(a1)[0][1]\n",
    "nb_classes = len(catogories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 데이터 - 원핫 인코딩\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 복원하기\n",
    "model1 = load_model('models/학습1.hdf5')\n",
    "model2 = load_model('models/학습2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 4s 4ms/step - loss: 3.4714 - accuracy: 0.5999\n",
      "오차 : 3.4714415073394775\n",
      "정확도 : 0.5999125242233276\n"
     ]
    }
   ],
   "source": [
    "# 변형된 이미지가 없는 데이터를 학습한 모델\n",
    "score1 = model1.evaluate(X_test, y_test)\n",
    "print(f'오차 : {score1[0]}')\n",
    "print(f'정확도 : {score1[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9943\n",
      "오차 : 0.025424981489777565\n",
      "정확도 : 0.9943156838417053\n"
     ]
    }
   ],
   "source": [
    "# 변형된 이미지가 포함된 데이터를 학습한 모델\n",
    "score2 = model2.evaluate(X_test, y_test)\n",
    "print(f'오차 : {score2[0]}')\n",
    "print(f'정확도 : {score2[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사진을 변형만 시켰는데 정확도가 엄청 향상됨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
